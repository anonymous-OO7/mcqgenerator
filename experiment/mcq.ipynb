{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476a7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x1202a1ca0> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1202a2210> model_name='llama-3.3-70b-versatile' model_kwargs={} groq_api_key=SecretStr('**********') Setup complete. You can now use the 'chain' object to generate names.\n",
      "GROKAI_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Setup the LLM\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# 2. Create a ChatPromptTemplate (Modern approach)\n",
    "# We use MessagesPlaceholder to dynamically inject the chat history\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful naming consultant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{product}\"),\n",
    "])\n",
    "\n",
    "# 3. Create the Chain using LCEL (Pipe operator |)\n",
    "chain = prompt | llm\n",
    "\n",
    "print(llm , \"Setup complete. You can now use the 'chain' object to generate names.\")\n",
    "KEY= os.getenv(\"GROKAI_API_KEY\")\n",
    "print(\"GROKAI_API_KEY:\", KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "#Project: MCQ Generator\n",
    "\n",
    "\n",
    "RESPONSE_JSON={\n",
    "    \"1\": {\n",
    "        \"no\": \"1\",\n",
    "        \"mcq\": \"multiple choice questions\",\n",
    "        \"options\":{\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \n",
    "    \"2\": {\n",
    "        \"no\": \"2\",\n",
    "        \"mcq\": \"multiple choice questions\",\n",
    "        \"options\":{\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \n",
    "    \"3\": {\n",
    "        \"no\": \"3\",\n",
    "        \"mcq\": \"multiple choice questions\",\n",
    "        \"options\":{\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \n",
    "        \"correct\": \"correct answer\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# 1st step design prompt using prompt template\n",
    "\n",
    "template=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "quiz_generation_prompt = PromptTemplate(input_varibale =  [\"text\", \"number\", \"grade\", \"tone\", \"response_json\"],template = template)\n",
    "\n",
    "print(\"Prompt template created successfully.\")\n",
    "\n",
    "chain = quiz_generation_prompt | llm\n",
    "result = chain.invoke({\"product\": \"drones\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of teh question and give a complete analysis of the quiz if the students\n",
    "will be able to unserstand the questions and answer them. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at par with the cognitive and analytical abilities of the students,\\\n",
    "update tech quiz questions which needs to be changed  and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "quiz_evaluation_prompt2=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=template)\n",
    "\n",
    "print(\"Prompt template created successfully.\")\n",
    "\n",
    "reviewchain = quiz_evaluation_prompt2 | llm\n",
    "result = chain.invoke({\"product\": \"drones\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7d93a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "class GroqCostHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.prompt_tokens = 0\n",
    "        self.completion_tokens = 0\n",
    "        self.successful_requests = 0\n",
    "        \n",
    "        # Pricing for Llama-3-70b (approximate Groq rates per 1M tokens)\n",
    "        # You can update these rates based on current Groq pricing\n",
    "        self.input_cost_per_1m = 0.59  # $0.59 per 1M input tokens\n",
    "        self.output_cost_per_1m = 0.79 # $0.79 per 1M output tokens\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        if response.llm_output and 'token_usage' in response.llm_output:\n",
    "            usage = response.llm_output['token_usage']\n",
    "            \n",
    "            # Update counts\n",
    "            self.prompt_tokens += usage.get('prompt_tokens', 0)\n",
    "            self.completion_tokens += usage.get('completion_tokens', 0)\n",
    "            self.total_tokens += usage.get('total_tokens', 0)\n",
    "            self.successful_requests += 1\n",
    "\n",
    "    def calculate_cost(self):\n",
    "        input_cost = (self.prompt_tokens / 1_000_000) * self.input_cost_per_1m\n",
    "        output_cost = (self.completion_tokens / 1_000_000) * self.output_cost_per_1m\n",
    "        return input_cost + output_cost\n",
    "\n",
    "    def print_report(self):\n",
    "        cost = self.calculate_cost()\n",
    "        print(f\"\\n--- Usage Report ---\")\n",
    "        print(f\"Requests:      {self.successful_requests}\")\n",
    "        print(f\"Input Tokens:  {self.prompt_tokens}\")\n",
    "        print(f\"Output Tokens: {self.completion_tokens}\")\n",
    "        print(f\"Total Tokens:  {self.total_tokens}\")\n",
    "        print(f\"Total Cost:    ${cost:.6f}\")\n",
    "        print(f\"--------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a545c130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### FINAL EVALUATION RESULT ###\n",
      "Complexity: Moderate to Challenging.\n",
      "\n",
      "To better fit student abilities, I suggest rephrasing questions for clarity and simplicity:\n",
      "\n",
      "1. What is photosynthesis used for in plants and some bacteria?\n",
      "   a) Releasing energy\n",
      "   b) Converting sunlight to chemical energy\n",
      "   c) Breaking down glucose\n",
      "   d) Producing water and carbon dioxide\n",
      "\n",
      "2. How many kinds of photosynthesis are discussed?\n",
      "   a) 1\n",
      "   b) 2\n",
      "   c) 3\n",
      "   d) 4\n",
      "\n",
      "3. What is produced during photosynthesis, besides glucose?\n",
      "   a) Carbon dioxide\n",
      "   b) Water\n",
      "   c) Oxygen\n",
      "   d) Light energy\n",
      "\n",
      "--- Usage Report ---\n",
      "Requests:      2\n",
      "Input Tokens:  719\n",
      "Output Tokens: 372\n",
      "Total Tokens:  1091\n",
      "Total Cost:    $0.000718\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "\n",
    "# 1. Setup LLM\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# 2. Define the Response Format\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"no\": \"1\",\n",
    "        \"mcq\": \"multiple choice questions\",\n",
    "        \"options\": {\"a\": \"...\", \"b\": \"...\", \"c\": \"...\", \"d\": \"...\"},\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"no\": \"2\",\n",
    "        \"mcq\": \"...\",\n",
    "        \"options\": {\"a\": \"...\", \"b\": \"...\", \"c\": \"...\", \"d\": \"...\"},\n",
    "        \"correct\": \"...\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"no\": \"3\",\n",
    "        \"mcq\": \"...\",\n",
    "        \"options\": {\"a\": \"...\", \"b\": \"...\", \"c\": \"...\", \"d\": \"...\"},\n",
    "        \"correct\": \"...\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1: MCQ GENERATION CHAIN\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "template1 = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \\\n",
    "Ensure to make {number} MCQs.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\"\n",
    "\n",
    "# FIXED: 'input_variables' spelling corrected\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=template1\n",
    ")\n",
    "\n",
    "# Chain 1: Generates the Quiz text\n",
    "# We add StrOutputParser() so the output is a string, not a message object\n",
    "quiz_chain = quiz_generation_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2: CRITIQUE/EVALUATION CHAIN\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "template2 = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz if the students\n",
    "will be able to unserstand the questions and answer them. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at par with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities.\n",
    "\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "# FIXED: used 'template=template2' (not template)\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=template2\n",
    ")\n",
    "\n",
    "# Chain 2: Generates the Review\n",
    "review_chain = quiz_evaluation_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3: CONNECTING THEM (SEQUENTIAL CHAIN)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# We use a dictionary to route arguments.\n",
    "# 1. \"quiz\" gets generated by running quiz_chain.\n",
    "# 2. \"subject\" is grabbed directly from the initial input using itemgetter.\n",
    "overall_chain = (\n",
    "    {\"quiz\": quiz_chain, \"subject\": itemgetter(\"subject\")}\n",
    "    | review_chain\n",
    ")\n",
    "\n",
    "# 2. Initialize the Handler\n",
    "cb = GroqCostHandler()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Sample text (Simulating your PDF text)\n",
    "sample_text = \"\"\"\n",
    "Photosynthesis is the process used by plants, algae and certain bacteria to harness energy from sunlight and turn it into chemical energy.\n",
    "There are two types of photosynthetic processes: oxygenic photosynthesis and anoxygenic photosynthesis.\n",
    "The general equation for photosynthesis is: 6CO2 + 6H2O + Light Energy -> C6H12O6 + 6O2.\n",
    "\"\"\"\n",
    "\n",
    "# Run the chain\n",
    "# Note: We pass 'json.dumps(RESPONSE_JSON)' to ensure the JSON guide is formatted as a string\n",
    "result = overall_chain.invoke({\n",
    "    \"text\": sample_text,\n",
    "    \"number\": \"3\",\n",
    "    \"subject\": \"Biology\",\n",
    "    \"tone\": \"Simple\",\n",
    "    \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "},config={'callbacks': [cb]}  )\n",
    "\n",
    "print(\"### FINAL EVALUATION RESULT ###\")\n",
    "print(result)\n",
    "\n",
    "# 4. Print the Cost Report\n",
    "cb.print_report()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
