{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d48e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys loaded successfully.\n",
      "Loading PDFs...\n",
      "Loaded 15 documents.\n",
      "Split into 52 chunks.\n",
      "Connecting to Hugging Face Embeddings...\n",
      "Generated vector of length: 384\n",
      "Index 'groq-rag-demo' already exists.\n",
      "‚ö†Ô∏è Clearing all existing vectors to prevent duplication...\n",
      "‚úÖ Index cleared.\n",
      "Uploading vectors to Pinecone...\n",
      "Upload complete!\n",
      "\n",
      "üîç Performing Similarity Search for: 'What is the summary of the document?'\n",
      "\n",
      "--- üìÑ Standard Search Results ---\n",
      "\n",
      "[Result 1]\n",
      "[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\n",
      "corpus of english: The penn treebank. Computational linguistics, 19(2):313‚Äì330, 1993.\n",
      "[26] David McCl...\n",
      "\n",
      "[Result 2]\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as ...\n",
      "\n",
      "[Result 3]\n",
      "Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\n",
      "model. All metrics are on the English-to-German translation development set, newstest2013. Liste...\n",
      "\n",
      "--- üìä Search Results with Scores ---\n",
      "\n",
      "[Result 1] Score: 0.3388\n",
      "[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\n",
      "corpus of english: The penn treebank. Computational linguistics, 19(2):313‚Äì330, 1993.\n",
      "[26] David McCl...\n",
      "\n",
      "[Result 2] Score: 0.2906\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as ...\n",
      "\n",
      "[Result 3] Score: 0.2423\n",
      "Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\n",
      "model. All metrics are on the English-to-German translation development set, newstest2013. Liste...\n",
      "\n",
      "‚úÖ Search Complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Imports\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# 1. LOAD KEYS\n",
    "load_dotenv()\n",
    "\n",
    "hf_api_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not all([hf_api_key, pinecone_api_key]):\n",
    "    raise ValueError(\"Error: Missing keys in .env file.\")\n",
    "\n",
    "print(\"Keys loaded successfully.\")\n",
    "\n",
    "# 2. LOAD & SPLIT DOCUMENTS\n",
    "print(\"Loading PDFs...\")\n",
    "loader = PyPDFDirectoryLoader(\"../pdfs/\") \n",
    "documents = loader.load()\n",
    "\n",
    "if not documents:\n",
    "    print(\"Warning: No documents found in ../pdfs/\")\n",
    "    final_documents = []\n",
    "else:\n",
    "    print(f\"Loaded {len(documents)} documents.\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    final_documents = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(final_documents)} chunks.\")\n",
    "\n",
    "# 3. SETUP EMBEDDINGS (YOUR WORKING CLASS)\n",
    "class RobustHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, api_key, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.client = InferenceClient(token=api_key)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings_list = []\n",
    "        for text in texts:\n",
    "            try:\n",
    "                response = self.client.feature_extraction(text, model=self.model_name)\n",
    "                if isinstance(response, np.ndarray):\n",
    "                    if response.ndim == 2:\n",
    "                        embedding = np.mean(response, axis=0).tolist()\n",
    "                    elif response.ndim == 1:\n",
    "                        embedding = response.tolist()\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected array dimensions: {response.ndim}\")\n",
    "                    embeddings_list.append(embedding)\n",
    "                elif isinstance(response, list):\n",
    "                    if len(response) > 0 and isinstance(response[0], list):\n",
    "                         embedding = np.mean(response, axis=0).tolist()\n",
    "                    else:\n",
    "                         embedding = response\n",
    "                    embeddings_list.append(embedding)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected response type: {type(response)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error embedding text: {e}\")\n",
    "                raise\n",
    "        return embeddings_list\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        result = self.embed_documents([text])\n",
    "        return result[0]\n",
    "\n",
    "print(\"Connecting to Hugging Face Embeddings...\")\n",
    "embeddings = RobustHuggingFaceEmbeddings(\n",
    "    api_key=hf_api_key,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\" \n",
    ")\n",
    "\n",
    "# 4. TEST EMBEDDINGS\n",
    "query_text = \"Hello, world!\"\n",
    "vector = embeddings.embed_query(query_text)\n",
    "print(f\"Generated vector of length: {len(vector)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. PINECONE SETUP (UPDATED: CLEARS DB FIRST)\n",
    "# ---------------------------------------------------------\n",
    "index_name = \"groq-rag-demo\"\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    print(f\"Creating index '{index_name}'...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    # Wait for index to initialize\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "    time.sleep(2)\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "    # --- NEW CODE: CLEAR INDEX ---\n",
    "    print(\"‚ö†Ô∏è Clearing all existing vectors to prevent duplication...\")\n",
    "    index = pc.Index(index_name)\n",
    "    index.delete(delete_all=True)\n",
    "    print(\"‚úÖ Index cleared.\")\n",
    "\n",
    "# 7. UPLOAD TO PINECONE\n",
    "if final_documents:\n",
    "    print(\"Uploading vectors to Pinecone...\")\n",
    "    vectorstore = PineconeVectorStore.from_documents(\n",
    "        documents=final_documents,\n",
    "        embedding=embeddings,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    print(\"Upload complete!\")\n",
    "else:\n",
    "    print(\"No documents to upload (Index is now empty).\")\n",
    "    vectorstore = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. SIMILARITY SEARCH IMPLEMENTATION\n",
    "# ---------------------------------------------------------\n",
    "query = \"What is the summary of the document?\"\n",
    "print(f\"\\nüîç Performing Similarity Search for: '{query}'\")\n",
    "\n",
    "# Method A: Standard Similarity Search (Get Top 3)\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(\"\\n--- üìÑ Standard Search Results ---\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n[Result {i+1}]\")\n",
    "    print(doc.page_content[:200] + \"...\") \n",
    "\n",
    "# Method B: Similarity Search with Scores (Cosine Similarity)\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(\"\\n--- üìä Search Results with Scores ---\")\n",
    "for i, (doc, score) in enumerate(results_with_scores):\n",
    "    print(f\"\\n[Result {i+1}] Score: {score:.4f}\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "\n",
    "print(\"\\n‚úÖ Search Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
